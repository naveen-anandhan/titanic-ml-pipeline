# ğŸš¢ Titanic Survival Prediction API

An end-to-end Production-Ready Machine Learning System that predicts whether a passenger survived the Titanic disaster.

This project demonstrates a real-world ML deployment pipeline including model training, API serving, containerization, release-based CI/CD, cloud deployment, and LLM-assisted error analysis.

---

## âœ¨ What This Project Demonstrates

* âœ… Data ingestion & preprocessing
* âœ… Feature engineering pipeline
* âœ… Model training & serialization
* âœ… Production inference pipeline
* âœ… FastAPI REST API
* âœ… Structured logging & custom exception handling
* âœ… ğŸ¤– LLM-powered error analysis & fix suggestion
* âœ… Docker containerization
* âœ… Release-driven CI/CD automation
* âœ… GitHub Container Registry (GHCR)
* âœ… Cloud deployment on Render
* âœ… Version traceability

---

## ğŸ§  Problem Statement

Given passenger attributes such as class, age, gender, fare, and embarkation port, predict whether the passenger survived the Titanic disaster.

---

# ğŸš€ Live Deployment

The service is deployed via **release-based CI/CD** using Docker images stored in GHCR.

### ğŸ”— API Base URL
https://titanic-api-8g3f.onrender.com

### ğŸ“˜ Swagger UI

https://titanic-api-8g3f.onrender.com/docs


### ğŸ§¾ Version Endpoint

```
GET /version
```

This ensures full traceability of the running production version.

---

# âš™ï¸ Tech Stack

* Python
* pandas
* scikit-learn
* FastAPI
* Uvicorn
* Docker
* GitHub Actions
* GitHub Container Registry (GHCR)
* Render (Cloud Hosting)

---

# ğŸ”’ Release & Deployment Strategy (Important)

This project follows a **Release-Driven Deployment Model**.

```
Push / Merge  â†’ NO DEPLOY âŒ  
Create Release â†’ BUILD â†’ DEPLOY ğŸš€
```

## ğŸ›  Deployment Workflow

1. Developers push or merge changes into `main`.
2. Production is NOT updated automatically.
3. When verified â†’ a GitHub Release is created.
4. Release triggers CI/CD.
5. Tests are executed.
6. Docker image is built using release version.
7. Image is pushed to GHCR.
8. Render pulls the new image and deploys.

---

## ğŸ§  Why This Approach?

* âœ… Prevents accidental production deployments.
* âœ… Every production version is traceable.
* âœ… Enables easy rollback.
* âœ… Guarantees reproducible builds.
* âœ… Follows real-world MLOps standards.

---

# ğŸ” CI/CD Pipeline

Triggered on **Release Publish**:

```
release 
   â†’ install dependencies 
   â†’ run tests 
   â†’ generate VERSION file 
   â†’ build Docker image 
   â†’ push to GHCR 
   â†’ trigger Render deploy
```

If tests fail â†’ deployment is blocked automatically.

---

# ğŸ“¦ Container Registry

Images are stored at:

```
ghcr.io/naveen-anandhan/titanic-ml-pipeline:<version>
ghcr.io/naveen-anandhan/titanic-ml-pipeline:latest
```

Each release creates an immutable, versioned container image.

---

# ğŸ· Versioning Policy

This project follows **Semantic Versioning (SemVer)**:

```
MAJOR.MINOR.PATCH
```

Example:

* `v1.2.0` â†’ New feature
* `v1.2.1` â†’ Bug fix
* `v2.0.0` â†’ Breaking change

âš ï¸ Released versions are immutable.
Bug fixes require a new patch version.

---

# ğŸ³ Run Using Docker

```bash
docker pull ghcr.io/naveen-anandhan/titanic-ml-pipeline:latest
docker run -p 8000:8000 ghcr.io/naveen-anandhan/titanic-ml-pipeline:latest
```

Access locally:

```
http://localhost:8000/docs
```

---

# ğŸ§ª Example Prediction Request

**POST** `/predict`

```json
{
  "PassengerId": 892,
  "Pclass": 3,
  "Name": "Kelly, Mr. James",
  "Sex": "male",
  "Age": 34.5,
  "SibSp": 0,
  "Parch": 0,
  "Ticket": "330911",
  "Fare": 7.8292,
  "Cabin": null,
  "Embarked": "Q"
}
```

---

# ğŸ§‘â€ğŸ’» Run Locally (Development Mode)

```bash
git clone https://github.com/naveen-anandhan/titanic-ml-pipeline.git
cd titanic-ml-pipeline

python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

uvicorn app:app --reload
```

---

# ğŸ§ª Run Tests

```bash
PYTHONPATH=. pytest
```

If tests fail â†’ CI blocks image build.

---

# ğŸ—ï¸ System Architecture

```
Client / User
      â”‚
      â–¼
FastAPI Application
      â”‚
      â”œâ”€â”€ SUCCESS FLOW
      â”‚      â†’ Load Serialized ML Pipeline
      â”‚      â†’ Generate Prediction
      â”‚      â†’ Return API Response
      â”‚
      â””â”€â”€ ERROR FLOW
             â†’ Exception Raised
             â†’ Exception Captured (Custom Handler)
             â†’ Structured Logging
             â†’ Send Error Context to LLM Service
             â†’ LLM Generates Suggested Fix
             â†’ Suggested Fix Logged
```

---

# ğŸ“ Project Structure

```
titanic-ml-pipeline/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ cicd.yml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ raw/
â”‚
â”œâ”€â”€ logs/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model_pipeline.pkl
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ notebooks/
â”œâ”€â”€ outputs/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ exception.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_app.py
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ main.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# ğŸŒ Deployment Philosophy

> **Build once â†’ Store in registry â†’ Deploy anywhere**

Each production version corresponds to an immutable Docker image.

---

# ğŸ‘¤ Author

**Naveen**

---
